{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embeddings', 'sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word length of questions in train is 134.\n",
      "Max word length of questions in test is 87.\n"
     ]
    }
   ],
   "source": [
    "print('Max word length of questions in train is {0:.0f}.'.format(np.max(train_df['question_text'].apply(lambda x: len(x.split())))))\n",
    "print('Max word length of questions in test is {0:.0f}.'.format(np.max(test_df['question_text'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length of questions in train is 71.\n",
      "Average character length of questions in test is 71.\n"
     ]
    }
   ],
   "source": [
    "print('Average character length of questions in train is {0:.0f}.'.format(np.mean(train_df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Average character length of questions in test is {0:.0f}.'.format(np.mean(test_df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(x):\n",
    "#     x = str(x)\n",
    "#     for punct in puncts:\n",
    "#         x = x.replace(punct, f' {punct} ')\n",
    "#     return x\n",
    "\n",
    "# puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    "#  '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    "#  '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    "#  '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    "#  '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_features = 100000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, lower=True)\n",
    "full_text = list(train_df['question_text'].values) + list(test_df['question_text'].values)\n",
    "tokenizer.fit_on_texts(full_text)\n",
    "\n",
    "train_tokenized = tokenizer.texts_to_sequences(train_df['question_text'].fillna('missing'))\n",
    "test_tokenized = tokenizer.texts_to_sequences(test_df['question_text'].fillna('missing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1306122\n",
      "<class 'list'>\n",
      "[16, 26, 1995, 375, 70, 26, 1995, 375, 450, 5341]\n",
      "Why does velocity affect time? Does velocity affect space geometry?\n",
      "[2, 12, 38, 222, 5, 13511, 28, 610, 10, 2, 12, 1, 1722, 7, 208, 17]\n",
      "What are some ways to shorten your period, and what are the risks of doing it?\n"
     ]
    }
   ],
   "source": [
    "print(len(train_tokenized))\n",
    "\n",
    "print(type(train_tokenized[2]))\n",
    "print(train_tokenized[2])\n",
    "print(train_df.question_text[2])\n",
    "print(train_tokenized[50])\n",
    "print(train_df.question_text[50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0   16   26 1995  375   70   26 1995  375\n",
      "  450 5341]\n",
      "(1306122, 72)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_len = 72\n",
    "train_X = pad_sequences(train_tokenized, maxlen=max_len)\n",
    "test_X = pad_sequences(test_tokenized, maxlen=max_len)\n",
    "train_y = train_df.target.values\n",
    "\n",
    "print(train_X[2])\n",
    "print(train_X.shape)\n",
    "# np.random.seed(0)\n",
    "# train_indices = np.random.permutation(len(train_X))\n",
    "\n",
    "# train_X = train_X[train_indices]\n",
    "# train_y = train_y[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 300)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_path= '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "news_path = '../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "embeddings = KeyedVectors.load_word2vec_format(news_path, binary=True)\n",
    "print(embeddings.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05419922  0.01708984 -0.00527954  0.33203125 -0.25       -0.01397705\n",
      " -0.15039062 -0.265625    0.01647949  0.3828125  -0.03295898 -0.09716797\n",
      " -0.16308594 -0.04443359  0.00946045  0.18457031  0.03637695  0.16601562\n",
      "  0.36328125 -0.25585938  0.375       0.171875    0.21386719 -0.19921875\n",
      "  0.13085938 -0.07275391 -0.02819824  0.11621094  0.15332031  0.09082031\n",
      "  0.06787109 -0.0300293  -0.16894531 -0.20800781 -0.03710938 -0.22753906\n",
      "  0.26367188  0.012146    0.18359375  0.31054688 -0.10791016 -0.19140625\n",
      "  0.21582031  0.13183594 -0.03515625  0.18554688 -0.30859375  0.04785156\n",
      " -0.10986328  0.14355469 -0.43554688 -0.0378418   0.10839844  0.140625\n",
      " -0.10595703  0.26171875 -0.17089844  0.39453125  0.12597656 -0.27734375\n",
      " -0.28125     0.14746094 -0.20996094  0.02355957  0.18457031  0.00445557\n",
      " -0.27929688 -0.03637695 -0.29296875  0.19628906  0.20703125  0.2890625\n",
      " -0.20507812  0.06787109 -0.43164062 -0.10986328 -0.2578125  -0.02331543\n",
      "  0.11328125  0.23144531 -0.04418945  0.10839844 -0.2890625  -0.09521484\n",
      " -0.10351562 -0.0324707   0.07763672 -0.13378906  0.22949219  0.06298828\n",
      "  0.08349609  0.02929688 -0.11474609  0.00534058 -0.12988281  0.02514648\n",
      "  0.08789062  0.24511719 -0.11474609 -0.296875   -0.59375    -0.29492188\n",
      " -0.13378906  0.27734375 -0.04174805  0.11621094  0.28320312  0.00241089\n",
      "  0.13867188 -0.00683594 -0.30078125  0.16210938  0.01171875 -0.13867188\n",
      "  0.48828125  0.02880859  0.02416992  0.04736328  0.05859375 -0.23828125\n",
      "  0.02758789  0.05981445 -0.03857422  0.06933594  0.14941406 -0.10888672\n",
      " -0.07324219  0.08789062  0.27148438  0.06591797 -0.37890625 -0.26171875\n",
      " -0.13183594  0.09570312 -0.3125      0.10205078  0.03063965  0.23632812\n",
      "  0.00582886  0.27734375  0.20507812 -0.17871094 -0.31445312 -0.01586914\n",
      "  0.13964844  0.13574219  0.0390625  -0.29296875  0.234375   -0.33984375\n",
      " -0.11816406  0.10644531 -0.18457031 -0.02099609  0.02563477  0.25390625\n",
      "  0.07275391  0.13574219 -0.00138092 -0.2578125  -0.2890625   0.10107422\n",
      "  0.19238281 -0.04882812  0.27929688 -0.3359375  -0.07373047  0.01879883\n",
      " -0.10986328 -0.04614258  0.15722656  0.06689453 -0.03417969  0.16308594\n",
      "  0.08642578  0.44726562  0.02026367 -0.01977539  0.07958984  0.17773438\n",
      " -0.04370117 -0.00952148  0.16503906  0.17285156  0.23144531 -0.04272461\n",
      "  0.02355957  0.18359375 -0.41601562 -0.01745605  0.16796875  0.04736328\n",
      "  0.14257812  0.08496094  0.33984375  0.1484375  -0.34375    -0.14160156\n",
      " -0.06835938 -0.14648438 -0.02844238  0.07421875 -0.07666016  0.12695312\n",
      "  0.05859375 -0.07568359 -0.03344727  0.23632812 -0.16308594  0.16503906\n",
      "  0.1484375  -0.2421875  -0.3515625  -0.30664062  0.00491333  0.17675781\n",
      "  0.46289062  0.14257812 -0.25       -0.25976562  0.04370117  0.34960938\n",
      "  0.05957031  0.07617188 -0.02868652 -0.09667969 -0.01281738  0.05859375\n",
      " -0.22949219 -0.1953125  -0.12207031  0.20117188 -0.42382812  0.06005859\n",
      "  0.50390625  0.20898438  0.11230469 -0.06054688  0.33203125  0.07421875\n",
      " -0.05786133  0.11083984 -0.06494141  0.05639648  0.01757812  0.08398438\n",
      "  0.13769531  0.2578125   0.16796875 -0.16894531  0.01794434  0.16015625\n",
      "  0.26171875  0.31640625 -0.24804688  0.05371094 -0.0859375   0.17089844\n",
      " -0.39453125 -0.00156403 -0.07324219 -0.04614258 -0.16210938 -0.15722656\n",
      "  0.21289062 -0.15820312  0.04394531  0.28515625  0.01196289 -0.26953125\n",
      " -0.04370117  0.37109375  0.04663086 -0.19726562  0.3046875  -0.36523438\n",
      " -0.23632812  0.08056641 -0.04248047 -0.14648438 -0.06225586 -0.0534668\n",
      " -0.05664062  0.18945312  0.37109375 -0.22070312  0.04638672  0.02612305\n",
      " -0.11474609  0.265625   -0.02453613  0.11083984 -0.02514648 -0.12060547\n",
      "  0.05297852  0.07128906  0.00063705 -0.36523438 -0.13769531 -0.12890625]\n"
     ]
    }
   ],
   "source": [
    "print((embeddings.get_vector('hello')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256198\n",
      "-0.003527845\n",
      "0.13315111\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.word_index))\n",
    "mean = np.mean(embeddings.vectors)\n",
    "std = np.std(embeddings.vectors)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "256198\n",
      "(100000, 300)\n"
     ]
    }
   ],
   "source": [
    "_, size = embeddings.vectors.shape\n",
    "print(size)\n",
    "print(len(tokenizer.word_index))\n",
    "num_words = min(len(tokenizer.word_index), max_features)\n",
    "embedding_matrix = np.random.normal(mean, std, (num_words, size))\n",
    "print(embedding_matrix.shape)\n",
    "# print(embedding_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 300)\n"
     ]
    }
   ],
   "source": [
    "for word, index in tokenizer.word_index.items():\n",
    "    if index >= max_features: continue\n",
    "    try:\n",
    "        word_vector = embeddings.get_vector(word)\n",
    "        embedding_matrix[index] = word_vector\n",
    "    except:\n",
    "        pass\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from tqdm import  tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def seed_torch(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed = 0\n",
    "seed_torch(seed)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(max_features, size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(3, size))\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(4, size))\n",
    "        self.conv_2 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(5, size))\n",
    "        self.fc = nn.Linear(3 * 100, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, text):\n",
    "#         print('text',text.shape)\n",
    "#         print('after',text.shape)\n",
    "        embedded = self.embedding(text)\n",
    "#         print('embedded', embedded.shape)\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "        conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim=1))\n",
    "        return self.fc(cat)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1306122, 72)\n",
      "<class 'numpy.ndarray'> (1306122,)\n",
      "Fold:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 \t loss=0.1206 \t val_loss=0.1146 \t time=84.12s\n",
      "Epoch 2/5 \t loss=0.1086 \t val_loss=0.1110 \t time=83.78s\n",
      "Epoch 3/5 \t loss=0.1003 \t val_loss=0.1113 \t time=83.97s\n",
      "Epoch 4/5 \t loss=0.0911 \t val_loss=0.1157 \t time=83.65s\n",
      "Epoch 5/5 \t loss=0.0824 \t val_loss=0.1192 \t time=83.68s\n",
      "Fold:1\n",
      "Epoch 1/5 \t loss=0.1207 \t val_loss=0.1202 \t time=83.79s\n",
      "Epoch 2/5 \t loss=0.1087 \t val_loss=0.1105 \t time=84.05s\n",
      "Epoch 3/5 \t loss=0.1003 \t val_loss=0.1116 \t time=83.74s\n",
      "Epoch 4/5 \t loss=0.0917 \t val_loss=0.1149 \t time=83.72s\n",
      "Epoch 5/5 \t loss=0.0835 \t val_loss=0.1215 \t time=84.22s\n",
      "Fold:2\n",
      "Epoch 1/5 \t loss=0.1208 \t val_loss=0.1120 \t time=83.78s\n",
      "Epoch 2/5 \t loss=0.1091 \t val_loss=0.1106 \t time=83.88s\n",
      "Epoch 3/5 \t loss=0.1008 \t val_loss=0.1102 \t time=83.97s\n",
      "Epoch 4/5 \t loss=0.0925 \t val_loss=0.1147 \t time=84.43s\n",
      "Epoch 5/5 \t loss=0.0837 \t val_loss=0.1196 \t time=83.92s\n",
      "Fold:3\n",
      "Epoch 1/5 \t loss=0.1208 \t val_loss=0.1119 \t time=83.84s\n",
      "Epoch 2/5 \t loss=0.1093 \t val_loss=0.1097 \t time=84.40s\n",
      "Epoch 3/5 \t loss=0.1012 \t val_loss=0.1128 \t time=83.84s\n",
      "Epoch 4/5 \t loss=0.0927 \t val_loss=0.1195 \t time=83.80s\n",
      "Epoch 5/5 \t loss=0.0839 \t val_loss=0.1206 \t time=83.80s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "splits = list(StratifiedKFold(n_splits=4, shuffle=True, random_state=0).split(train_X, train_y))\n",
    "train_epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "print(type(train_X), train_X.shape)\n",
    "print(type(train_y), train_y.shape)\n",
    "train_X = torch.Tensor(train_X)\n",
    "train_y = torch.Tensor(train_y)\n",
    "\n",
    "train_preds = np.zeros((len(train_X)))\n",
    "test_preds = np.zeros((len(test_X)))\n",
    "\n",
    "x_test_cuda = torch.tensor(test_X, dtype=torch.long).cuda()\n",
    "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "    print('Fold:{0}'.format(i))\n",
    "    x_train_fold = torch.tensor(train_X[train_idx], dtype=torch.long).cuda()\n",
    "    y_train_fold = torch.tensor(train_y[train_idx, np.newaxis], dtype=torch.float32).cuda()\n",
    "    x_val_fold = torch.tensor(train_X[valid_idx], dtype=torch.long).cuda()\n",
    "    y_val_fold = torch.tensor(train_y[valid_idx, np.newaxis], dtype=torch.float32).cuda()\n",
    "    \n",
    "    train_data = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
    "    valid_data = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = CNN()\n",
    "    model.cuda()\n",
    "    loss_function = nn.BCEWithLogitsLoss()\n",
    "    optimiser = optim.Adam(model.parameters())\n",
    "    \n",
    "    for epoch in range(train_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        avg_loss = 0.0\n",
    "        # train  model\n",
    "        for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
    "#             print(x_batch.shape)\n",
    "#             print(y_batch.shape)\n",
    "            y_predicted = model(x_batch)\n",
    "#             print(y_predicted.shape)\n",
    "#             print(y_predicted[0])\n",
    "            loss = loss_function(y_predicted, y_batch)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            avg_loss += loss.item()/len(train_loader)\n",
    "\n",
    "    # evaluate model\n",
    "        model.eval()\n",
    "        val_predicted_fold = np.zeros(x_val_fold.size(0))\n",
    "        test_predicted_fold = np.zeros(len(test_X))\n",
    "        avg_val_loss =0.0\n",
    "\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            y_predicted = model(x_batch).detach()\n",
    "            avg_val_loss += loss_function(y_predicted, y_batch).item()/len(valid_loader)\n",
    "            val_predicted_fold[i*batch_size:(i+1)*batch_size] = sigmoid(y_predicted.cpu().numpy())[:,0]   \n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(epoch + 1,\n",
    "                                                        train_epochs, avg_loss, avg_val_loss, elapsed_time))\n",
    "    # test model on testing dataset\n",
    "    test_predicted_fold = np.zeros(len(test_X))\n",
    "    for i, (x_batch,) in enumerate(test_loader):\n",
    "        y_pred = model(x_batch).detach()\n",
    "        test_predicted_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "    \n",
    "    train_preds[valid_idx] = val_predicted_fold\n",
    "    test_preds += test_predicted_fold / len(splits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in tqdm([i * 0.01 for i in range(100)]):\n",
    "        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'f1': best_score}\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:29<00:00,  3.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'threshold': 0.26, 'f1': 0.6311257860553635}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = threshold_search(train_y, train_preds)\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub.prediction = test_preds > search_result['threshold']\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operator \n",
    "# def check_coverage(vocab,embeddings):\n",
    "#     a = {}\n",
    "#     oov = {}\n",
    "#     k = 0\n",
    "#     i = 0\n",
    "#     for word in tqdm(vocab):\n",
    "#         try:\n",
    "#             a[word] = embeddings[word]\n",
    "#             k += vocab[word]\n",
    "#         except:\n",
    "\n",
    "#             oov[word] = vocab[word]\n",
    "#             i += vocab[word]\n",
    "#             pass\n",
    "\n",
    "#     print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "#     print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "#     sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "#     return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
